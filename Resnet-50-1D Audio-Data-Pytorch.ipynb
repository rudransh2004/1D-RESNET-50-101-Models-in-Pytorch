{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffd8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.load(\"audio_data.npy\")\n",
    "y = np.load(\"audio_target.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, random_state=42)\n",
    "x_train = np.expand_dims(X_train,axis=-1)\n",
    "x_test = np.expand_dims(X_test,axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4834b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensor_x = torch.Tensor(x_train)\n",
    "tensor_x_test = torch.Tensor(x_test)\n",
    "# transform to torch tensor\n",
    "tensor_y = torch.Tensor(y_train)\n",
    "tensor_y = tensor_y.type(torch.LongTensor)\n",
    "tensor_y_test = torch.tensor(y_test)\n",
    "tensor_y_test = tensor_y_test.type(torch.LongTensor)\n",
    "\n",
    "\n",
    "my_dataset_train = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test)\n",
    "\n",
    "\n",
    "my_dataloader_train = DataLoader(my_dataset_train,batch_size =32) \n",
    "my_dataloader_test = DataLoader(my_dataset_test,batch_size = 32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e14db872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import Resnet\n",
    "\n",
    "def Resnet50(layers = [3,4,6,3],data_channels=40, num_classes=6):\n",
    "    return Resnet(layers, data_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5a18f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model \n",
    "import torch\n",
    "net = Resnet50()\n",
    "y = net(torch.randn(32,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86f54631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 26.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.23076924681663513\n",
      "Val_Accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.38461539149284363\n",
      "Val_Accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.3076923191547394\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 27.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5384615659713745\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6153846383094788\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.46153849363327026\n",
      "Val_Accuracy=0.4000000059604645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.46153849363327026\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6153846383094788\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.46153849363327026\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 175/175 [00:06<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6153846383094788\n",
      "Val_Accuracy=0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "net = Resnet50().to(\"cuda:0\")\n",
    "criterion = nn.CrossEntropyLoss().to(\"cuda:0\")\n",
    "optimizer = optim.Adam(net.parameters(),lr = 3e-4)\n",
    "for epochs in range(0,10):\n",
    "    correct_train = 0\n",
    "    correct_validation = 0\n",
    "    net.train(True)\n",
    "    for i,(x_batch,y_batch) in enumerate(tqdm(my_dataloader_train)):\n",
    "        #print(x_batch.shape)\n",
    "        #print(y_batch.shape)\n",
    "        y_pred = net(x_batch.to('cuda:0')).cuda()\n",
    "        #print(y_pred.argmax(axis=1))\n",
    "        #print(y_pred)\n",
    "        loss = criterion(y_pred.to(\"cuda:0\"),y_batch.cuda())\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(y_pred.argmax(axis=1))\n",
    "        #print(y_batch.cuda())\n",
    "        train_acc = torch.sum(y_pred.argmax(axis=1).cuda() == y_batch.cuda())\n",
    "        #correct_train  += (y_pred.argmax(axis=1).cuda() == y_batch.cuda()).float().sum()\n",
    "        #print(correct_train)\n",
    "    accuracy = train_acc/len(x_batch)\n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    net.train(False)\n",
    "    running_vloss = 0.0\n",
    "    for i,(x_batch_t,y_batch_t) in enumerate(my_dataloader_test):\n",
    "        voutputs = net(x_batch_t.to(\"cuda:0\")).cuda()\n",
    "        vloss = criterion(voutputs.to(\"cuda:0\"), y_batch_t.cuda())\n",
    "        val_acc = torch.sum(voutputs.argmax(axis=1).cuda() == y_batch_t.cuda())\n",
    "        #print(voutputs.argmax(axis=1))\n",
    "        #print(y_batch_t.cuda())\n",
    "        #correct_validation += (voutputs.argmax(axis=1).cuda()==y_batch_t.cuda()).float().sum()\n",
    "    accuracy_val = val_acc /len(x_batch_t)   \n",
    "    print(\"Val_Accuracy={}\".format(accuracy_val))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99e196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
